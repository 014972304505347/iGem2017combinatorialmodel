{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 70367,
          "databundleVersionId": 9188054,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "ADC24",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/014972304505347/iGem2017combinatorialmodel/blob/master/ADC24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'ariel-data-challenge-2024:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F70367%2F9188054%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240803%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240803T235650Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4e77a6799dbb45f00cdaa640ac68167dae92f92f61a312079559ac4992210b1757d8287896ac8bc00fb5aedff96fa88ce6219c4b40d36bbd46928572de07b2e0e4ab8fa1ca70020b6c6843ed55f5e1ba96548b52182db313b3b895118e59c060b514d326dd2bd099a157488d77b3fa0851045a7969b028d4356ae09286afc3f1798b3a037ef5ee0e93be2a4ff989df2080c60206c4826e59557c0ea6d4883c02731a1d4e07be4fe9056eb27f92cbbe74461fb93d54a4d2ccca59ed705218464c106cca29a3ec344c9f54f90bb1dc5e12c7608c6135df6bd0f9026e45b669e35d87587c629ce124c70263cdcba5fd351c36450024864e1fa3747355362a2df0fa'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "d5paftpGrLXy"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ariel Data Challenge 2024: Quickstart ⭐️⭐️⭐️⭐️⭐️\n",
        "\n",
        "In this notebook, we show how to make predictions using only the FGS1 data.\n",
        "\n",
        "Of course, we cross-validate our model before preparing a submission.\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "pE-h9AN8rLX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import scipy.stats\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import r2_score, mean_squared_error"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-08-03T23:50:25.02156Z",
          "iopub.execute_input": "2024-08-03T23:50:25.021944Z",
          "iopub.status.idle": "2024-08-03T23:50:28.417761Z",
          "shell.execute_reply.started": "2024-08-03T23:50:25.021913Z",
          "shell.execute_reply": "2024-08-03T23:50:28.416585Z"
        },
        "trusted": true,
        "id": "Qy1M6JiArLX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following hidden cell contains the function which evaluates the competition metric."
      ],
      "metadata": {
        "id": "VQ9hszrTrLX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapted from https://www.kaggle.com/code/metric/ariel-gaussian-log-likelihood\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "def competition_score(\n",
        "        solution: pd.DataFrame,\n",
        "        submission: pd.DataFrame,\n",
        "        naive_mean: float,\n",
        "        naive_sigma: float,\n",
        "        sigma_true: float,\n",
        "        row_id_column_name='planet_id',\n",
        "    ) -> float:\n",
        "    '''\n",
        "    This is a Gaussian Log Likelihood based metric. For a submission, which contains the predicted mean (x_hat) and variance (x_hat_std),\n",
        "    we calculate the Gaussian Log-likelihood (GLL) value to the provided ground truth (x). We treat each pair of x_hat,\n",
        "    x_hat_std as a 1D gaussian, meaning there will be 283 1D gaussian distributions, hence 283 values for each test spectrum,\n",
        "    the GLL value for one spectrum is the sum of all of them.\n",
        "\n",
        "    Inputs:\n",
        "        - solution: Ground Truth spectra (from test set)\n",
        "            - shape: (nsamples, n_wavelengths)\n",
        "        - submission: Predicted spectra and errors (from participants)\n",
        "            - shape: (nsamples, n_wavelengths*2)\n",
        "        naive_mean: (float) mean from the train set.\n",
        "        naive_sigma: (float) standard deviation from the train set.\n",
        "        sigma_true: (float) essentially sets the scale of the outputs.\n",
        "    '''\n",
        "\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    if submission.min().min() < 0:\n",
        "        raise ParticipantVisibleError('Negative values in the submission')\n",
        "    for col in submission.columns:\n",
        "        if not pd.api.types.is_numeric_dtype(submission[col]):\n",
        "            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n",
        "\n",
        "    n_wavelengths = len(solution.columns)\n",
        "    if len(submission.columns) != n_wavelengths*2:\n",
        "        raise ParticipantVisibleError('Wrong number of columns in the submission')\n",
        "\n",
        "    y_pred = submission.iloc[:, :n_wavelengths].values\n",
        "    # Set a non-zero minimum sigma pred to prevent division by zero errors.\n",
        "    sigma_pred = np.clip(submission.iloc[:, n_wavelengths:].values, a_min=10**-15, a_max=None)\n",
        "    y_true = solution.values\n",
        "\n",
        "    GLL_pred = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_pred, scale=sigma_pred))\n",
        "    GLL_true = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_true, scale=sigma_true * np.ones_like(y_true)))\n",
        "    GLL_mean = np.sum(scipy.stats.norm.logpdf(y_true, loc=naive_mean * np.ones_like(y_true), scale=naive_sigma * np.ones_like(y_true)))\n",
        "\n",
        "    submit_score = (GLL_pred - GLL_mean)/(GLL_true - GLL_mean)\n",
        "    return float(np.clip(submit_score, 0.0, 1.0))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-08-03T23:50:28.420488Z",
          "iopub.execute_input": "2024-08-03T23:50:28.42111Z",
          "iopub.status.idle": "2024-08-03T23:50:28.438065Z",
          "shell.execute_reply.started": "2024-08-03T23:50:28.421069Z",
          "shell.execute_reply": "2024-08-03T23:50:28.435874Z"
        },
        "trusted": true,
        "id": "AXU6p5B9rLX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the data\n",
        "\n",
        "We start by reading the metadata:"
      ],
      "metadata": {
        "id": "z7Wm1D0TrLX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_adc_info.csv',\n",
        "                           index_col='planet_id')\n",
        "test_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/test_adc_info.csv',\n",
        "                           index_col='planet_id')\n",
        "train_labels = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_labels.csv',\n",
        "                           index_col='planet_id')\n",
        "wavelengths = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/wavelengths.csv')\n",
        "#axis_info = pd.read_parquet('/kaggle/input/ariel-data-challenge-2024/axis_info.parquet')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-03T23:50:28.445268Z",
          "iopub.execute_input": "2024-08-03T23:50:28.445648Z",
          "iopub.status.idle": "2024-08-03T23:50:28.639031Z",
          "shell.execute_reply.started": "2024-08-03T23:50:28.445605Z",
          "shell.execute_reply": "2024-08-03T23:50:28.637696Z"
        },
        "trusted": true,
        "id": "8zCnbx5DrLX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some facts about the data:\n",
        "- We have 673 planets of 2 stars for training.\n",
        "- There are roughly 800 planets for testing (but the test data is hidden).\n",
        "- The competition is a multi-output regression task with 283 wavelengths to predict. The first one is from FGS1, the other 282 are from AIRS."
      ],
      "metadata": {
        "id": "SGeAtflVrLX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading and preprocessing the FGS1 data\n",
        "\n",
        "The FGS1 measurements consist of one file per planet (673 files for 673 planets for training). For now, we ignore the calibration files.\n",
        "\n",
        "Each file contains 135,000 rows of images taken at 0.1 second time steps. Each row is a 32\\*32 image at a single wavelength.\n",
        "\n",
        "We read a sample file:"
      ],
      "metadata": {
        "id": "pIwHI3qUrLX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planet_id = 14485303\n",
        "f_signal = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/train/{planet_id}/FGS1_signal.parquet')\n",
        "f_signal"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-03T23:50:28.640765Z",
          "iopub.execute_input": "2024-08-03T23:50:28.641248Z",
          "iopub.status.idle": "2024-08-03T23:50:30.568689Z",
          "shell.execute_reply.started": "2024-08-03T23:50:28.6412Z",
          "shell.execute_reply": "2024-08-03T23:50:30.567438Z"
        },
        "trusted": true,
        "id": "eVE29fyCrLX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every row of the file corresponds to an image of a star:"
      ],
      "metadata": {
        "id": "WisZkd4RrLX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(f_signal.iloc[1].values.reshape(32, 32))\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-08-03T23:50:30.570362Z",
          "iopub.execute_input": "2024-08-03T23:50:30.570875Z",
          "iopub.status.idle": "2024-08-03T23:50:31.093829Z",
          "shell.execute_reply.started": "2024-08-03T23:50:30.570832Z",
          "shell.execute_reply": "2024-08-03T23:50:31.092394Z"
        },
        "trusted": true,
        "id": "O8K6o2GnrLX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the time series, we first have to compute the difference between the even and the odd frames to get the net signal. The net signal is very noisy, and we smoothen it by computing a moving average. The plot of the smoothened signal clearly shows that the image gets darker while the planet passes in front of the star (between time steps 22000 and 45000)."
      ],
      "metadata": {
        "id": "xm8F4-7JrLX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_signal = f_signal.values.mean(axis=1)\n",
        "net_signal = mean_signal[1::2] - mean_signal[0::2]\n",
        "cum_signal = net_signal.cumsum()\n",
        "window=800\n",
        "smooth_signal = (cum_signal[window:] - cum_signal[:-window]) / window\n",
        "\n",
        "_, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "ax1.plot(net_signal, label='raw net signal')\n",
        "ax1.legend()\n",
        "ax2.plot(smooth_signal, color='c', label='smoothened net signal')\n",
        "ax2.legend()\n",
        "ax2.set_xlabel('time')\n",
        "plt.suptitle('FGS1 time series', y=0.96)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-08-03T23:50:31.095557Z",
          "iopub.execute_input": "2024-08-03T23:50:31.096066Z",
          "iopub.status.idle": "2024-08-03T23:50:32.188044Z",
          "shell.execute_reply.started": "2024-08-03T23:50:31.096026Z",
          "shell.execute_reply": "2024-08-03T23:50:32.186699Z"
        },
        "trusted": true,
        "id": "DvYVdI-nrLX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now read the FGS1 data for all 673 training planets. We keep only three values for every planet: The mean signal before, during and after the planet passes in front of the star."
      ],
      "metadata": {
        "id": "lhXDbXevrLX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def f_read_and_preprocess(dataset, adc_info):\n",
        "    \"\"\"Read the FGS1 files for all planet_ids and extract the signal.\n",
        "\n",
        "    Parameters\n",
        "    dataset: 'train' or 'test'\n",
        "    adc_info: metadata dataframe, either train_adc_info or test_adc_info\n",
        "\n",
        "    Returns\n",
        "    dataframe with one row per planet_id\n",
        "\n",
        "    \"\"\"\n",
        "    planet_ids = adc_info.index\n",
        "    phases = []\n",
        "    for i, planet_id in tqdm(list(enumerate(planet_ids))):\n",
        "        f_signal = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/{planet_id}/FGS1_signal.parquet')\n",
        "        mean_signal = f_signal.values.mean(axis=1) # mean over the 32*32 pixels\n",
        "        net_signal = mean_signal[1::2] - mean_signal[0::2]\n",
        "\n",
        "        gain = adc_info.FGS1_adc_gain.values[i]\n",
        "        phase1 = net_signal[:18000].mean() * gain\n",
        "        phase2 = net_signal[25000:40000].mean() * gain\n",
        "        phase3 = net_signal[50000:].mean() * gain\n",
        "\n",
        "        phases.append((phase1, phase2, phase3))\n",
        "    return pd.DataFrame(phases, columns=['phase0', 'phase1', 'phase2'])\n",
        "\n",
        "train = f_read_and_preprocess('train', train_adc_info)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-03T23:50:32.189654Z",
          "iopub.execute_input": "2024-08-03T23:50:32.190153Z"
        },
        "trusted": true,
        "id": "tockr2JgrLX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following scatterplot shows a strong correlation between the signal reduction when the planet is in front of the star and one of the targets we want to predict. The other targets have a similarly high correlation."
      ],
      "metadata": {
        "id": "-6Ir7ZkSrLX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(train.phase0 - train.phase1, train_labels.wl_1, color='g', s=15)\n",
        "plt.xlabel('signal reduction when planet is in front')\n",
        "plt.ylabel('target')\n",
        "plt.title('Correlation between signal reduction and target')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Q8LF_ySErLX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The model and the cross-validation\n",
        "\n",
        "To keep things simple, we predict the spectra with ridge regression.\n",
        "\n",
        "We are interested in three cross-validation metrics:\n",
        "1. The R2 score is above 0.9, which confirms the correlation we've seen in the scatterplot.\n",
        "2. The root mean squared error will be the predicted uncertainty.\n",
        "3. The competition metric gives an indication of the leaderboard score. Unfortunately the competition metric depends on the value of `sigma_true`, which I don't know."
      ],
      "metadata": {
        "id": "Rr5bn_jErLX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = make_pipeline(PolynomialFeatures(include_bias=False), Ridge())\n",
        "model = Ridge()\n",
        "\n",
        "oof_pred = cross_val_predict(model, train, train_labels)\n",
        "\n",
        "print(f\"# R2 score: {r2_score(train_labels, oof_pred):.3f}\")\n",
        "sigma_pred = mean_squared_error(train_labels, oof_pred, squared=False)\n",
        "print(f\"# Root mean squared error: {sigma_pred:.6f}\")\n",
        "\n",
        "col = 1\n",
        "plt.scatter(oof_pred[:,col], train_labels.iloc[:,col], s=15, c='lightgreen')\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.xlabel('y_pred')\n",
        "plt.ylabel('y_true')\n",
        "plt.title('Comparing y_true and y_pred')\n",
        "plt.show()\n",
        "\n",
        "# R2 score: 0.924\n",
        "# Root mean squared error: 0.000474"
      ],
      "metadata": {
        "trusted": true,
        "id": "HARNibuqrLX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataframe(pred_array, index, sigma_pred):\n",
        "    return pd.concat([pd.DataFrame(pred_array.clip(train_labels.values.min(), train_labels.values.max()), index=index, columns=wavelengths.columns),\n",
        "                      pd.DataFrame(sigma_pred, index=index, columns=[f\"sigma_{i}\" for i in range(1, 284)])],\n",
        "                     axis=1)\n",
        "\n",
        "oof_df = make_dataframe(oof_pred, train_adc_info.index, sigma_pred)\n",
        "display(oof_df)\n",
        "\n",
        "gll_score = competition_score(train_labels.copy().reset_index(),\n",
        "                              oof_df.copy().reset_index(),\n",
        "                              naive_mean=train_labels.values.mean(),\n",
        "                              naive_sigma=train_labels.values.std(),\n",
        "                              sigma_true=0.0001)\n",
        "print(f\"# Estimated competition score: {gll_score:.3f}\")\n",
        "# Estimated competition score: 0.389"
      ],
      "metadata": {
        "trusted": true,
        "id": "nzm9t8pqrLX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "Fhhz52ZdrLX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Refit the model to the full dataset\n",
        "model.fit(train, train_labels)\n",
        "\n",
        "# Predict\n",
        "test = f_read_and_preprocess('test', test_adc_info)\n",
        "test_pred = model.predict(test)\n",
        "\n",
        "# Package into submission file\n",
        "sub = make_dataframe(test_pred, test_adc_info.index, sigma_pred)\n",
        "display(sub)\n",
        "sub.to_csv('submission.csv')\n",
        "#!head submission.csv"
      ],
      "metadata": {
        "trusted": true,
        "id": "0NfOCnfXrLX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outlook: The AIRS measurements\n",
        "\n",
        "AIRS is the other sensor of the satellite. Again, it produces one file per planet.\n",
        "\n",
        "Each file contains 11,250 rows of images captured at constant time steps. Each 32 x 356 image has been flattened into 11392 columns."
      ],
      "metadata": {
        "id": "5_UOqhLtrLX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_signal = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/train/{planet_id}/AIRS-CH0_signal.parquet')\n",
        "a_signal"
      ],
      "metadata": {
        "trusted": true,
        "id": "2V50QwMLrLX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_signal = a_signal.values.reshape(11250, 32, 356)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "TCkNKWwkrLX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 3))\n",
        "sns.heatmap(a_signal[1])\n",
        "plt.ylabel('spatial dimension')\n",
        "plt.xlabel('wavelength dimension')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "rj0-A7zirLX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data again is a time series, and we can see the star being obscured while the planet is passing in front of it."
      ],
      "metadata": {
        "id": "zf1RLbJ-rLX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_signal = a_signal.mean(axis=2).mean(axis=1)\n",
        "net_signal = mean_signal[1::2] - mean_signal[0::2]\n",
        "cum_signal = net_signal.cumsum()\n",
        "window=80\n",
        "smooth_signal = (cum_signal[window:] - cum_signal[:-window]) / window\n",
        "\n",
        "_, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "ax1.plot(net_signal, label='raw net signal')\n",
        "ax1.legend()\n",
        "ax2.plot(smooth_signal, color='c', label='smoothened net signal')\n",
        "ax2.legend()\n",
        "ax2.set_xlabel('time')\n",
        "plt.suptitle('AIRS-CH0 time series', y=0.96)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "sdn5winsrLX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJv2NSlLrLX5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}